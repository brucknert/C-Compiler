%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Encoding: utf8
% Project: VYPe - Compiler Construction
% Authors:
%     	Filip Benna, xbenna01
%		Tomáš Bruckner, xbruck02
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
This documentation is describing the implementation of the compiler for VYPe16 programming language. It is a project for the course VYPe Compiler Construction is taught at Faculty of Information Technology at Brno University of Technology. VYPe16 is a limited version of C language. The source code is compiled to the MIPS32 instruction set. Full specification can be found at 

\section{Front-end implementation}
The front-end of the compiler is doing analysis of the given source code. It checks for lexical errors, syntactic errors and semantic errors. During the analysis, it creates parse trees that are used as the input for the back-end part of the compiler. For easier implementation of the front-end, ANTLR4 framework has been used. In this framework, tokens and grammar rules are defined and it generates Java classes and interfaces, that are used for the scanner and the parser.

\subsection{Lexical analysis}
For the lexical analysis, a lexer grammar has been defined in the file \textit{VYPeLexer}. The lexer grammar is basically a set of the rules (tokens) defined by something similiar to the regular expressions. Some rules has been defined, so that white spaces, line comments and block comments are skipped. There was an option to send them to different channel (HIDDEN channel is recommended as best practice) instead of skipping them, but there was no use for them later, so it was decided to skip them.

The rules of the lexer grammar are used by ANTLR4 to generate VYPeLexer class, that is used for creating a token input stream. This token stream is later used as input for the parser class described below \ref{sec:syntax}.

One special rule (token) has been defined that is not in a specification, \textit{Error} token. ANTLR4 has not got the best support for detecting lexical errors. The way it should be detected is using \textit{DefaultErrorStrategy} class, but it has some problems, so it was decided that we will create special \textit{Error} token, that catches every invalid tokens. It is later checked if any \textit{Error} token has been encountered, in which case the program ends with a lexical error code.


\subsection{Syntactic analysis}
\label{sec:syntax}
For the syntactic analysis, grammar rules has been defined in the file \textit{VYPeParser}. Unfortunately, ANTLR4 cannot handle \textit{EOF} token in the first rule, so there is a special rule \textit{parse}, that just takes one alternative rule \textit{start}, which is the start rule for the grammar.

Based on the grammar rules, ANTLR4 generates parser class, that parses input token stream. The parser rule \textit{start} is checked, because it is the starting rule for VYPe16 language. In case of the syntactic error, the program ends with a syntactic error code. It can be easily checked, because the parser class stores the number of the syntactic errors in its instance.

There was also a problem with defining operators with same priority. For different priority, it is quite easy. They just have to be defined in an order from the highest priority to the lowest. For same priority, the dynamic rule has been used. It specified alternatives with the same priority. It could also be defined, but this is clearer solution.

Labels for rule alternatives were sometimes used, because it made semantic analysis easier. Visitor/listener class takes all labels and creates parsing methods for them. The rules are specified in the grammar below \ref{sec:grammar}. 

\subsection{Semantic analysis}
For the semantic analysis, visitor and listener classes were used. \textit{FunctionTable} class is used for tracking what functions are already declared or defined. \textit{SymbolTable} class is used for tracking all variables in current scope. For the nested scopes, every symbol table can have a reference to its parent scope (symbol table).

There was also a problem, that there had to be some way, how to track type of current expression. This problem was resolved by \textit{Value} interface and a few implementations of the interface for each data type. These classes are also used when a new function is declared/defined. They are used for the parameters declaration/definition. There was a problem with embedded function \textit{print}, because it has variable number of parameters. It was solved by defining \textit{VariableValue} class that implements \textit{Value} interface and represents, that the function has variable number of parameters. For user defined functions, there are listeners that parses all parameters and stores them in function table.

Semantic check takes function declarations and definitions sequentially and looks into function table if there is no other declaration/definition of the same function. In case there is, throws \textit{SemanticException}. If it is a function definition, the body of the function is checked. No variables cannot be used if it was not declared before. Symbol table is used for this case. Similarly, there cannot be any function calls if the function has not been already declared (function table is used). Every expression type is checked. It has to correspond to expected type. For instance, if there is an addition of a number and function call that returns string type, \textit{SemanticException} is thrown. 


 

\subsection{Grammar}
\label{sec:grammar}

TODO ADD GRAMMAR!!!!!!!!!!

\section{Back-end implementation}
The back-end of the compiler takes as the input the parse tree generated by the ANTLR4 framework and checked by the front-end. The output of the compiler is MIPS-32 assembly. The main implementation is split into three main classes: \textit{ASMProgram} (referenced as \textit{Program}), \textit{ASMRegisterAllocator} (referenced as \textit{RegisterAllocator}), \textit{VYPe*Low} (set of classes implementing visitors of various source language constructs). Each of the target language elements, such as instructions, registers, labels etc. is implemented in its own class, which is mainly responsible for the correct text output representation of the element.

\subsection{Source code language lowering}
Each language construct in the source code language is lowered (translated into functionally equivalent construct in the target language) into the target language when the corresponding node is visited in the parse tree. If such node has some children (such as operands of algebraic operations), these children are lowered into the target code first and the result is returned into the parent node in a form of a variable representing result value of the lowering (in case of a expression). Each language construct is lowered the same way each time, which means that it is not respected, whether the operands are present in memory or register, so no instruction selection is performed. The exception are constructs which respect the data type of the operands (mentioned later). Once the target code for the current parse tree node is generated, it is passed into the \textit{Program}, which is responsible for collecting generated instruction, labels, directives and static data. Once the whole tree is traversed \textit{Program} converts the internal representation into text which is printed into the output file. Program is also responsible for generating unique names of auxiliary labels and generating data section storing strings created by user in the source code.

\subsection{Value representation}
There are generally two types of variables used during the target code generation.
\begin{itemize}
\item \textbf{User variables} which were declared by the user in the source code. These variables are represented by its name which was chosen by the user.
\item \textbf{Temporary variables} which are needed as temporary results while computing subexpressions. These variables are created during the target code representation and are represented by a unique index.  
\end{itemize} 
All the variables are handled and stored inside the \textit{RegisterAllocator} which is informed about newly declared variables and newly needed temporary variables by the source code lowering. Variables are assigned to a currently visited scope of code. These scopes are stored in a stack also inside the \textit{RegisterAllocator}. This way it is possible to handle same user variables defined in different scopes.
Variables are in back-end represented by its location. It means that it is not known what is the value of such variable (even if it is a constant) but where is the value stored. The location can be either register or memory. During the target code lowering the values are represented by these variables even though the instructions operate with registers. The reason is that it is unknown how much code will be generated before the result of one expression will be used as a operand in another one and so the result value can be meanwhile moved from a register into the memory (spilled). \textit{RegisterAllocator} serves as a level of abstraction for the source code lowering because this way it is not necessary to consider the location of operands while generating the target code. When a variable is needed as a operand \textit{RegisterAllocator} is asked to return this variable in a register. Inside the \textit{RegisterAllocator} it is decided whether this variable is already present in a register or not. If not a free register is chosen to be used as a new location for the variable. If there is no free register, a victim is chosen and spilled into the memory. Victim is chosen based on the \textit{LRU} algorithm. All the code necessary for storing values from registers into the memory and loading new values into the registers is generated inside the \textit{RegisterAllocator} so it is completely transparent for the source code lowering part of the back-end.

\subsection{Data types}
\textit{Int} data type values and \textit{char} data type values can be in most situations treated exactly the same way. The reason for this is that both of them can fit into a single register. However the \textit{string} data type variables behave differently. Each string is in the target program represented by a pointer to the memory where the string is stored. This can be either \textit{data} section in case of the string literals used in the program or heap in case of strings given by the user of the program from standard input. Heap also stores strings which were created as modification of already existing string. This happens when embedded functions are called. Since these function are not supposed to modify the source string, it is first copied onto heap and the copy is modified as user wants. Strings also can not be compared as easily as other data types. It has to be done in a loop byte by byte.

\subsection{Memory}
Apart from registers there are three memory segments used during the compilation.
\begin{itemize}
\item \textbf{Data section} - stores string literals used in the program and starts in memory where the text segment ends.
\item \textbf{Heap} - used to store copies of strings which are about to be modified. Also strings set from the standard input and strings set to the default value ares stored here. The start address for heap is set to \textit{0x1000}, which leaves \textit{0x1000} bytes for the code and static data. The current top of the heap is stored in the global pointer register and is modified each time new string is stored here.
\item \textbf{Stack} - probably the most important segment of the memory. Stack is used for local variables which were spilled from register and also to store a call frame when a function is called. In such situation all the registers containing valid values are stored onto the stack except for stack pointer itself which is backed up by the callee function and reset back to the original value before return from the function. Also all the function parameters are stored onto stack which means that registers are not used for parameter passing. The top of the stack is set to \textit{0x4000} which means that there is a total of \textit{0x3000} bytes for both stack and heap (each grows in opposite direction). There is no check implemented for stack overflow.
\end{itemize}

\section{Interesting problems}
This section deals with problems which were encountered during the compiler implementation. It is not a total list of such problems, only the ones we find interesting, and maybe difficult to understand if found in produced target code, are mentioned here.
\begin{itemize}
\item \textbf{Default return value} - the source language defines default return value which should be used when user does not specify one. This can be solved by placing new return statement at the end of each function, which would be used only if user does not specify one. This would, however, lead to not necessary increase of the code size. Therefore there is a simple analysis implemented to prevent this. In case there is a return statement placed in the root scope of a function, the default return statement is not generated. In case of return statement used in conditional statement or loop body the default return statement is still generated since without a control-flow analysis it is impossible to determine whether such return statement will be executed.
\item \textbf{Default variable value} - each declared variable does not have to be defined by the user and still the value of the variable at the point of the first usage is specified by the language specification. Our first implementation produced load of the default value in such situation exactly at the point of the first usage of the variable. This was not the solution we could use, even though it was very good implementation to deal with the register pressure, since this first usage might happen in a loop. Without any further analysis this was not possible to determine, so it is necessary to load the default value into the variable right at the point of its declaration.
\item \textbf{Function name mangling} - the provided assembler can not deal with symbols of a name which conflicts with any of the instructions. Since user can not be restricted in the way he/she names his/her functions further than what is specified by the source language we had to implement very simple function name mangling. The only symbol which stays unmodified is the main function. This is done due to the fact that generally the start-up code can be from a different source which would expect symbol main to be present in the output object file.
\end{itemize}

\section{Literature}
Literature used, including citations of any non-original materials (pictures, statistics
etc.).